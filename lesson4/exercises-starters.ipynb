{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "This is the notebook containing the exercises for Feature Store, Model Monitor, and Clarify. Tested for these exercises was performed using __2 vCPU + 4 GiB notebook instance with Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized) kernel__.\n",
    "\n",
    "## Staging\n",
    "\n",
    "We'll begin by initializing some variables. These are often assumed to be present in code samples you'll find in the AWS documenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature store is a special database to give ML systems a consistent data flow across training and inference workloads. It can ingest data in batches (for training) as well as serve input features to models with very low latency for real-time prediction.\n",
    "\n",
    "For this exercise we'll work with a wine quality dataset: https://archive.ics.uci.edu/ml/datasets/wine+quality/\n",
    "\n",
    "```P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we leave the column names as-is, Feature Store won't be able to handle the `/` in `od280/od315_of_diluted_wines` (`/` is a delimiter Feature Store uses to manage how features are organized.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data, we can create a feature group. Remember to attach event time and ID columns - Feature Store needs them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='alcohol', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='malic_acid', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='alcalinity_of_ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='magnesium', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='total_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='flavanoids', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='nonflavanoid_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='proanthocyanins', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='color_intensity', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='hue', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='od280_od315_of_diluted_wines', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='proline', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='EventTime', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>, collection_type=None),\n",
       " FeatureDefinition(feature_name='id', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>, collection_type=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a feature group\n",
    "df[\"EventTime\"] = time.time()\n",
    "df[\"id\"] = range(len(df))\n",
    "\n",
    "# TODO: Create feature group\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "name = f\"wine-feature-group-{uuid.uuid4()}\"\n",
    "feature_group = FeatureGroup(name=name, sagemaker_session=session)\n",
    "\n",
    "# TODO: Load Feature definitions\n",
    "feature_group.load_feature_definitions(data_frame=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature group is not created until we call the `create` method, let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:002427974286:feature-group/wine-feature-group-0b660e83-a372-4026-a4b3-7dd2ae073a37',\n",
       " 'ResponseMetadata': {'RequestId': 'a386dc55-eee0-4589-b1c2-6c8d450eeb47',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a386dc55-eee0-4589-b1c2-6c8d450eeb47',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '132',\n",
       "   'date': 'Wed, 16 Oct 2024 23:01:57 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = \"udacity-landingzone\"\n",
    "\n",
    "# Create the feature store:\n",
    "feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/lesson4-sagemaker/feature-store/wine-feature-group\",\n",
    "    record_identifier_name='id',\n",
    "    event_time_feature_name='EventTime',\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, ingest some data into your feature group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='wine-feature-group-0b660e83-a372-4026-a4b3-7dd2ae073a37', feature_definitions={'alcohol': {'FeatureName': 'alcohol', 'FeatureType': 'Fractional'}, 'malic_acid': {'FeatureName': 'malic_acid', 'FeatureType': 'Fractional'}, 'ash': {'FeatureName': 'ash', 'FeatureType': 'Fractional'}, 'alcalinity_of_ash': {'FeatureName': 'alcalinity_of_ash', 'FeatureType': 'Fractional'}, 'magnesium': {'FeatureName': 'magnesium', 'FeatureType': 'Fractional'}, 'total_phenols': {'FeatureName': 'total_phenols', 'FeatureType': 'Fractional'}, 'flavanoids': {'FeatureName': 'flavanoids', 'FeatureType': 'Fractional'}, 'nonflavanoid_phenols': {'FeatureName': 'nonflavanoid_phenols', 'FeatureType': 'Fractional'}, 'proanthocyanins': {'FeatureName': 'proanthocyanins', 'FeatureType': 'Fractional'}, 'color_intensity': {'FeatureName': 'color_intensity', 'FeatureType': 'Fractional'}, 'hue': {'FeatureName': 'hue', 'FeatureType': 'Fractional'}, 'od280_od315_of_diluted_wines': {'FeatureName': 'od280_od315_of_diluted_wines', 'FeatureType': 'Fractional'}, 'proline': {'FeatureName': 'proline', 'FeatureType': 'Fractional'}, 'EventTime': {'FeatureName': 'EventTime', 'FeatureType': 'Fractional'}, 'id': {'FeatureName': 'id', 'FeatureType': 'Integral'}}, sagemaker_fs_runtime_client_config=<botocore.config.Config object at 0x7fc341312110>, sagemaker_session=<sagemaker.session.Session object at 0x7fc3491bfe50>, max_workers=3, max_processes=1, profile_name=None, _async_result=<multiprocess.pool.MapResult object at 0x7fc33ebb1690>, _processing_pool=<pool ProcessPool(ncpus=1)>, _failed_indices=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "# Ingest data into the feature store\n",
    "feature_group.ingest(data_frame=df, max_workers=3, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You've demonstrated your understanding of creating feature groups and ingesting data into them using Feature Store. Next up we'll cover Model Monitor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll create a monitoring schedule for a deployed model. We're going to provide code to help you deploy a model and get started, so that you can focus on Model Monitor for this exercise. __Remember to clean up your model before you end a work session__. We'll provide some code at the end to help you clean up your model. We'll begin by reloading our data from the previous exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: xgboost-2024-10-16-23-09-58-994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-16 23:10:00 Starting - Starting the training job...\n",
      "2024-10-16 23:10:15 Starting - Preparing the instances for training...\n",
      "2024-10-16 23:10:43 Downloading - Downloading input data...\n",
      "2024-10-16 23:11:15 Downloading - Downloading the training image...\n",
      "2024-10-16 23:12:01 Training - Training image download completed. Training in progress...\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2024-10-16:23:12:14:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2024-10-16:23:12:14:INFO] File size need to be processed in the node: 0.01mb. Available memory size in the node: 8461.38mb\u001b[0m\n",
      "\u001b[34m[2024-10-16:23:12:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:12:14] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:12:14] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2024-10-16:23:12:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:12:14] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:12:14] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.759657#011validation-rmse:0.685354\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.616137#011validation-rmse:0.821641\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.501087#011validation-rmse:0.858446\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.430041#011validation-rmse:0.925116\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.377443#011validation-rmse:0.979923\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.337549#011validation-rmse:1.0265\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.309158#011validation-rmse:1.06425\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.287472#011validation-rmse:1.09787\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.273879#011validation-rmse:1.12296\u001b[0m\n",
      "\u001b[34m[23:12:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.264732#011validation-rmse:1.1432\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\n",
      "2024-10-16 23:12:33 Uploading - Uploading generated training model\n",
      "2024-10-16 23:12:33 Completed - Training job completed\n",
      "Training seconds: 109\n",
      "Billable seconds: 109\n"
     ]
    }
   ],
   "source": [
    "algo_image = sagemaker.image_uris.retrieve(\"xgboost\", region, version='latest')\n",
    "s3_output_location = f\"s3://{bucket}/lesson4-sagemaker/model/wine_model\"\n",
    "\n",
    "model=sagemaker.estimator.Estimator(\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "model.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)\n",
    "\n",
    "\n",
    "model.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your training job has finished, you can perform the first task in this exercise: creating a data capture config. Configure your model to sample `34%` of inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "capture_uri = f\"s3://{bucket}/lesson4-sagemaker/monitor/data-capture\"\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=capture_uri,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We'll use your config to deploy a model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: xgboost-2024-10-16-23-15-38-613\n",
      "INFO:sagemaker:Creating endpoint-config with name xgboost-2024-10-16-23-15-38-613\n",
      "INFO:sagemaker:Creating endpoint with name xgboost-2024-10-16-23-15-38-613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You should see an indicator like this when the deployment finishes:\n",
    "\n",
    "```\n",
    "-----------------!\n",
    "```\n",
    "We can test your deployment like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6030303239822388,0.6030303239822388,0.6030303239822388,0.6030303239822388,0.6030303239822388'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "inputs = test.copy()\n",
    "# Drop the target variable\n",
    "inputs = inputs.drop(columns=inputs.columns[0])\n",
    "x_pred = xgb_predictor.predict(inputs.sample(5).values).decode('utf-8')\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All systems go! To finish up the exercise, we're going to provide you with a DefaultModelMonitor and a suggested baseline. Combine the `xgb_predictor` and the provided `my_monitor` to configure the monitoring schedule for _hourly_ monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2024-10-16-23-25-54-497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........\u001b[34m2024-10-16 23:27:43.870564: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:43.870602: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:45.473549: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:45.473579: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:45.473599: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-129-184.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:45.473863: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,074 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:002427974286:processing-job/baseline-suggestion-job-2024-10-16-23-25-54-497', 'ProcessingJobName': 'baseline-suggestion-job-2024-10-16-23-25-54-497', 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-002427974286/data/train.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinitionInput': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-east-1-002427974286/model-monitor/baselining/baseline-suggestion-job-2024-10-16-23-25-54-497/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'NetworkConfig': {'VpcConfig': None, 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False}, 'RoleArn': 'arn:aws:iam::002427974286:role/UdacitySageMakerStepFunctionExecutionRole', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,074 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,074 - __main__ - INFO - categorical_drift_method:None\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,074 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"exclude_features_attribute\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"data_quality_monitoring_config\": {\"evaluate_constraints\": \"Enabled\", \"emit_metrics\": \"Enabled\", \"datatype_check_threshold\": 1.0, \"domain_content_threshold\": 1.0, \"distribution_constraints\": {\"perform_comparison\": \"Enabled\", \"comparison_threshold\": 0.1, \"comparison_method\": \"Robust\", \"categorical_comparison_threshold\": 0.1, \"categorical_drift_method\": \"LInfinity\"}}, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,074 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,074 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,121 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,122 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,122 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'current_instance_type': 'ml.m5.xlarge', 'current_group_name': 'homogeneousCluster', 'hosts': ['algo-1'], 'instance_groups': [{'instance_group_name': 'homogeneousCluster', 'instance_type': 'ml.m5.xlarge', 'hosts': ['algo-1']}], 'network_interface_name': 'eth0'}\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,129 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,129 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,129 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,603 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.129.184\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-\u001b[0m\n",
      "\u001b[34mnodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_392\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,613 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:47,616 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-16ddf932-a6fa-4d1f-bb85-0594cc2809bc\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,130 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,141 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,142 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,144 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,149 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,149 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,149 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,149 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,181 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,192 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,192 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,196 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,200 INFO blockmanagement.BlockManager: The block deletion will start around 2024 Oct 16 23:27:48\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,201 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,201 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,203 INFO util.GSet: 2.0% max memory 3.1 GB = 62.7 MB\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,203 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,238 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,242 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,242 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,242 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,242 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,242 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,242 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,242 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,242 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,243 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,243 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,243 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,268 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,269 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,269 INFO util.GSet: 1.0% max memory 3.1 GB = 31.3 MB\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,269 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,271 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,271 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,271 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,271 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,275 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,279 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,279 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,279 INFO util.GSet: 0.25% max memory 3.1 GB = 7.8 MB\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,279 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,315 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,315 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,315 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,319 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,319 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,320 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,320 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,321 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 962.9 KB\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,321 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,344 INFO namenode.FSImage: Allocated new BlockPoolId: BP-597742326-10.0.129.184-1729121268337\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,355 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,362 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,447 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,457 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,461 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.129.184\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:48,473 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:50,532 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:50,532 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:52,592 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:52,592 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:54,664 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:54,664 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:56,762 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:56,763 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:58,876 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:27:58,877 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:08,888 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:10,621 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,037 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,075 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,085 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,621 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,647 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,648 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,648 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,649 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,673 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 3, script: , vendor: , memory -> name: memory, amount: 11507, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,688 INFO resource.ResourceProfile: Limiting resource is cpus at 3 tasks per executor\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,690 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,743 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,744 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,744 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,744 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:11,745 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,086 INFO util.Utils: Successfully started service 'sparkDriver' on port 32893.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,114 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,153 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,181 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,182 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,227 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,258 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-fdb31d5c-347d-4e71-bb08-d38bb1284100\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,282 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,335 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,380 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.129.184:32893/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1729121291617\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:12,919 INFO client.RMProxy: Connecting to ResourceManager at /10.0.129.184:8032\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:13,603 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:13,604 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:13,610 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (15692 MB per container)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:13,611 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:13,611 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:13,611 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:13,617 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:13,695 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:15,865 INFO yarn.Client: Uploading resource file:/tmp/spark-56c15ca6-32a1-46bc-a3dd-dce83a3e000c/__spark_libs__5450635612395621668.zip -> hdfs://10.0.129.184/user/root/.sparkStaging/application_1729121274140_0001/__spark_libs__5450635612395621668.zip\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:16,993 INFO yarn.Client: Uploading resource file:/tmp/spark-56c15ca6-32a1-46bc-a3dd-dce83a3e000c/__spark_conf__8487136797627077479.zip -> hdfs://10.0.129.184/user/root/.sparkStaging/application_1729121274140_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:17,051 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:17,051 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:17,051 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:17,051 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:17,051 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:17,080 INFO yarn.Client: Submitting application application_1729121274140_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:17,276 INFO impl.YarnClientImpl: Submitted application application_1729121274140_0001\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:18,280 INFO yarn.Client: Application report for application_1729121274140_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:18,283 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Wed Oct 16 23:28:18 +0000 2024] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1729121297181\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1729121274140_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:19,285 INFO yarn.Client: Application report for application_1729121274140_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:20,288 INFO yarn.Client: Application report for application_1729121274140_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:21,291 INFO yarn.Client: Application report for application_1729121274140_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:22,295 INFO yarn.Client: Application report for application_1729121274140_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:22,728 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1729121274140_0001), /proxy/application_1729121274140_0001\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,299 INFO yarn.Client: Application report for application_1729121274140_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,300 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.129.184\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1729121297181\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1729121274140_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,302 INFO cluster.YarnClientSchedulerBackend: Application application_1729121274140_0001 has started running.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,314 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44881.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,314 INFO netty.NettyBlockTransferService: Server created on 10.0.129.184:44881\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,316 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,326 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.129.184, 44881, None)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,335 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.129.184:44881 with 1458.6 MiB RAM, BlockManagerId(driver, 10.0.129.184, 44881, None)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,339 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.129.184, 44881, None)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,340 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.129.184, 44881, None)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:23,500 INFO util.log: Logging initialized @14358ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:24,184 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:28,512 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.129.184:60058) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:28,691 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:40675 with 5.8 GiB RAM, BlockManagerId(1, algo-1, 40675, None)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:42,872 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:43,077 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:43,137 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:43,141 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:44,276 INFO datasources.InMemoryFileIndex: It took 40 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:44,443 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:44,720 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:44,723 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.129.184:44881 (size: 39.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:44,728 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,064 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,067 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,069 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 6004\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,144 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,163 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,163 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,164 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,165 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,170 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,214 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,217 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,218 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.129.184:44881 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,219 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,236 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,237 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,281 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4618 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:45,561 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:40675 (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,313 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:40675 (size: 39.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,659 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1393 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,661 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,667 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 1.465 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,671 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,672 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,674 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 1.529576 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,844 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.129.184:44881 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:46,845 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:40675 in memory (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:48,956 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:48,958 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:48,961 INFO datasources.FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 12 more fields>\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,141 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,155 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,156 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.129.184:44881 (size: 39.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,157 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,170 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,216 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:124\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,218 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:124) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,218 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:124)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,218 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,221 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,223 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,276 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 17.4 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,278 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,279 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.129.184:44881 (size: 8.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,280 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,280 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:124) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,281 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,285 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:49,324 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:40675 (size: 8.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,076 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:40675 (size: 39.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,172 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:40675 (size: 10.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,306 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1024 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,306 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,308 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:124) finished in 1.082 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,311 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,311 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,312 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:124, took 1.095666 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:50,575 INFO codegen.CodeGenerator: Code generated in 190.834406 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,125 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,277 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,281 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,282 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,282 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,285 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,287 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,314 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 114.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,316 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,317 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.129.184:44881 (size: 34.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,318 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,320 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,321 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,329 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:51,364 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:40675 (size: 34.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,444 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1116 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,445 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,446 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.155 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,447 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,447 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,448 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,448 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,535 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,538 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,538 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,539 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,539 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,540 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,551 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 166.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,554 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 45.9 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,554 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.129.184:44881 (size: 45.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,555 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,556 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,556 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,559 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,584 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:40675 (size: 45.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,628 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,973 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 415 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,974 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.428 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,974 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,976 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,977 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:52,977 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.441182 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,024 INFO codegen.CodeGenerator: Code generated in 35.274499 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,460 INFO codegen.CodeGenerator: Code generated in 52.545012 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,586 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,587 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,587 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,587 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,588 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,590 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,662 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.129.184:44881 in memory (size: 8.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,679 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:40675 in memory (size: 8.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,699 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 38.2 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,701 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,711 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.129.184:44881 (size: 16.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,712 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,712 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,712 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,715 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,727 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.129.184:44881 in memory (size: 45.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,737 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:40675 in memory (size: 45.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,738 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:40675 (size: 16.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,773 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:40675 in memory (size: 34.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:53,776 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.129.184:44881 in memory (size: 34.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,160 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 445 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,160 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,164 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 0.573 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,164 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,165 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,165 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 0.578959 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,679 INFO codegen.CodeGenerator: Code generated in 110.886356 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,688 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,688 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,688 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,688 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,689 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,690 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,698 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 74.1 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,700 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,701 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.129.184:44881 (size: 23.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,701 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,702 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,702 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,704 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,715 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:40675 (size: 23.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,793 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 90 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,793 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,794 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.103 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,795 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,796 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,796 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:54,796 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,090 INFO codegen.CodeGenerator: Code generated in 136.6877 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,113 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,115 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,116 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,116 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,116 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,117 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,126 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.5 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,128 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,129 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.129.184:44881 (size: 19.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,129 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,130 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,130 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,131 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,145 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:40675 (size: 19.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,151 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,284 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 153 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,284 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,285 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.161 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,285 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,286 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,291 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.177421 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,363 INFO codegen.CodeGenerator: Code generated in 43.979852 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,457 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,460 INFO scheduler.DAGScheduler: Registering RDD 45 (countByKey at ColumnProfiler.scala:592) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,461 INFO scheduler.DAGScheduler: Got job 7 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,461 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,461 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,461 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,463 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,471 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.5 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,473 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,474 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.129.184:44881 (size: 13.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,474 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,475 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,475 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,477 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:55,502 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:40675 (size: 13.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,772 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 1296 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,772 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,773 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (countByKey at ColumnProfiler.scala:592) finished in 1.309 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,773 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,773 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,773 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,773 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,774 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,788 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,797 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,798 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.129.184:44881 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,800 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,801 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[46] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,802 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,805 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,820 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:40675 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,828 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,903 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 99 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,904 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,905 INFO scheduler.DAGScheduler: ResultStage 10 (countByKey at ColumnProfiler.scala:592) finished in 0.129 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,906 INFO scheduler.DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,907 INFO cluster.YarnScheduler: Killing all running tasks in stage 10: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:56,907 INFO scheduler.DAGScheduler: Job 7 finished: countByKey at ColumnProfiler.scala:592, took 1.450307 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,234 INFO scheduler.DAGScheduler: Registering RDD 51 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,235 INFO scheduler.DAGScheduler: Got map stage job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,235 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,235 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,236 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,237 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,246 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 83.3 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,248 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 27.3 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,249 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.129.184:44881 (size: 27.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,250 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,250 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,252 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,255 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,270 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:40675 (size: 27.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,436 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 181 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,436 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,437 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (collect at AnalysisRunner.scala:326) finished in 0.196 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,437 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,438 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,438 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,438 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,494 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,496 INFO scheduler.DAGScheduler: Got job 9 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,496 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,496 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,496 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,497 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,505 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 167.9 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,507 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 46.0 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,508 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.129.184:44881 (size: 46.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,510 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,511 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,511 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,512 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,522 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:40675 (size: 46.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,532 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,612 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 100 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,612 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,613 INFO scheduler.DAGScheduler: ResultStage 13 (collect at AnalysisRunner.scala:326) finished in 0.113 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,614 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,615 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,615 INFO scheduler.DAGScheduler: Job 9 finished: collect at AnalysisRunner.scala:326, took 0.120427 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,740 INFO codegen.CodeGenerator: Code generated in 16.835587 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,773 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,774 INFO scheduler.DAGScheduler: Got job 10 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,774 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,774 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,776 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,777 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,786 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 38.1 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,789 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,790 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.129.184:44881 (size: 16.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,799 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,799 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,799 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,801 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,816 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:40675 (size: 16.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,887 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 86 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,887 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,888 INFO scheduler.DAGScheduler: ResultStage 14 (treeReduce at KLLRunner.scala:107) finished in 0.110 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,889 INFO scheduler.DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,889 INFO cluster.YarnScheduler: Killing all running tasks in stage 14: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:57,890 INFO scheduler.DAGScheduler: Job 10 finished: treeReduce at KLLRunner.scala:107, took 0.116804 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,067 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:40675 in memory (size: 16.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,076 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.129.184:44881 in memory (size: 16.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,082 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:40675 in memory (size: 27.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,087 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.129.184:44881 in memory (size: 27.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,104 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.129.184:44881 in memory (size: 13.9 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,121 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:40675 in memory (size: 13.9 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,148 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.129.184:44881 in memory (size: 23.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,154 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:40675 in memory (size: 23.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,155 INFO codegen.CodeGenerator: Code generated in 97.502425 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,173 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:40675 in memory (size: 16.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,174 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.129.184:44881 in memory (size: 16.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,176 INFO scheduler.DAGScheduler: Registering RDD 69 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,177 INFO scheduler.DAGScheduler: Got map stage job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,177 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,177 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,178 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,178 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,189 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 73.6 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,191 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,192 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.129.184:44881 (size: 23.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,192 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,193 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[69] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,193 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,194 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,209 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:40675 (size: 23.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,210 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.129.184:44881 in memory (size: 46.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,219 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:40675 in memory (size: 46.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,250 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:40675 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,251 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.129.184:44881 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,321 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.129.184:44881 in memory (size: 19.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,325 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:40675 in memory (size: 19.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,331 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 137 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,331 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,332 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (collect at AnalysisRunner.scala:326) finished in 0.147 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,333 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,333 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,334 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,334 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,484 INFO codegen.CodeGenerator: Code generated in 67.994791 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,501 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,503 INFO scheduler.DAGScheduler: Got job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,503 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,503 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,504 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,504 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,508 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 66.2 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,510 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,511 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.129.184:44881 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,511 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,512 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,512 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,513 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,524 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:40675 (size: 19.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,528 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,629 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 13) in 116 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,629 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,630 INFO scheduler.DAGScheduler: ResultStage 17 (collect at AnalysisRunner.scala:326) finished in 0.123 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,631 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,632 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,632 INFO scheduler.DAGScheduler: Job 12 finished: collect at AnalysisRunner.scala:326, took 0.130647 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,714 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,716 INFO scheduler.DAGScheduler: Registering RDD 80 (countByKey at ColumnProfiler.scala:592) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,717 INFO scheduler.DAGScheduler: Got job 13 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,717 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,717 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,718 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 18)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,720 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,728 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 30.5 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,730 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,731 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.129.184:44881 (size: 14.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,732 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,734 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[80] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,735 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,736 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,752 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:40675 (size: 14.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,828 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 14) in 92 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,828 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,829 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (countByKey at ColumnProfiler.scala:592) finished in 0.108 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,830 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,830 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,831 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 19)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,831 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,831 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,833 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,835 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,836 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.129.184:44881 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,837 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,837 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (ShuffledRDD[81] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,838 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,839 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,852 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:40675 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,857 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,892 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 53 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,892 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,893 INFO scheduler.DAGScheduler: ResultStage 19 (countByKey at ColumnProfiler.scala:592) finished in 0.061 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,893 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,893 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:58,894 INFO scheduler.DAGScheduler: Job 13 finished: countByKey at ColumnProfiler.scala:592, took 0.179324 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,071 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,071 INFO scheduler.DAGScheduler: Got map stage job 14 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,071 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,071 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,071 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,072 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,075 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 73.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,076 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,077 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.129.184:44881 (size: 25.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,077 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,078 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,078 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,079 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 16) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,106 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:40675 (size: 25.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,303 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 16) in 224 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,303 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,304 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.231 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,304 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,304 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,304 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,304 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,357 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,358 INFO scheduler.DAGScheduler: Got job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,358 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,358 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,358 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,359 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,370 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 141.6 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,373 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 40.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,374 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.129.184:44881 (size: 40.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,376 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,377 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,377 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,380 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,397 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:40675 (size: 40.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,407 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,556 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 177 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,556 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,557 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.198 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,557 INFO scheduler.DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,557 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,557 INFO scheduler.DAGScheduler: Job 15 finished: collect at AnalysisRunner.scala:326, took 0.199918 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,595 INFO codegen.CodeGenerator: Code generated in 34.094593 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,725 INFO codegen.CodeGenerator: Code generated in 23.516447 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,769 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,770 INFO scheduler.DAGScheduler: Got job 16 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,770 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,770 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,771 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,771 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,779 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 37.2 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,785 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 16.1 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,785 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.129.184:44881 (size: 16.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,787 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,787 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[99] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,788 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,792 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 18) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,809 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:40675 (size: 16.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,893 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 18) in 101 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,893 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,894 INFO scheduler.DAGScheduler: ResultStage 23 (treeReduce at KLLRunner.scala:107) finished in 0.122 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,895 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,895 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:28:59,896 INFO scheduler.DAGScheduler: Job 16 finished: treeReduce at KLLRunner.scala:107, took 0.126642 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,107 INFO codegen.CodeGenerator: Code generated in 69.02121 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,115 INFO scheduler.DAGScheduler: Registering RDD 104 (collect at AnalysisRunner.scala:326) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,115 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,115 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,116 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,116 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,117 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,120 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 63.3 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,122 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,123 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.129.184:44881 (size: 20.8 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,124 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,128 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[104] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,128 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,129 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,143 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:40675 (size: 20.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,212 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 19) in 83 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,213 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,214 INFO scheduler.DAGScheduler: ShuffleMapStage 24 (collect at AnalysisRunner.scala:326) finished in 0.096 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,215 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,216 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,216 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,217 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,446 INFO codegen.CodeGenerator: Code generated in 125.021699 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,460 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,462 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,464 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,464 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,465 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,465 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,470 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 55.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,473 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,474 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.129.184:44881 (size: 16.7 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,476 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,477 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,478 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,479 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 20) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,490 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:40675 (size: 16.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,495 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,583 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 20) in 104 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,583 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,584 INFO scheduler.DAGScheduler: ResultStage 26 (collect at AnalysisRunner.scala:326) finished in 0.116 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,585 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,585 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,585 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.124075 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,625 INFO codegen.CodeGenerator: Code generated in 26.450746 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,682 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,683 INFO scheduler.DAGScheduler: Registering RDD 115 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,684 INFO scheduler.DAGScheduler: Got job 19 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,684 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,684 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,685 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 27)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,686 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,691 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 30.5 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,693 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,693 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.129.184:44881 (size: 14.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,694 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,694 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,694 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,696 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,705 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:40675 (size: 14.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,773 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 77 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,774 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,775 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (countByKey at ColumnProfiler.scala:592) finished in 0.086 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,775 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,775 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,775 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 28)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,775 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,775 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,777 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 5.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,778 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,779 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.129.184:44881 (size: 3.0 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,779 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,780 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,780 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,781 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 22) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,796 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:40675 (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,799 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,820 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 22) in 39 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,820 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,821 INFO scheduler.DAGScheduler: ResultStage 28 (countByKey at ColumnProfiler.scala:592) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,821 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,821 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:00,822 INFO scheduler.DAGScheduler: Job 19 finished: countByKey at ColumnProfiler.scala:592, took 0.139528 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,042 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,083 INFO codegen.CodeGenerator: Code generated in 15.841526 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,090 INFO scheduler.DAGScheduler: Registering RDD 121 (count at StatsGenerator.scala:66) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,090 INFO scheduler.DAGScheduler: Got map stage job 20 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,090 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,090 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,090 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,091 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[121] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,094 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 22.5 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,119 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 1456.9 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,121 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.129.184:44881 (size: 10.4 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,122 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,122 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[121] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,122 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,124 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 23) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4935 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,140 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:40675 (size: 10.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,161 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.129.184:44881 in memory (size: 19.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,196 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:40675 in memory (size: 19.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,200 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 23) in 75 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,200 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,200 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (count at StatsGenerator.scala:66) finished in 0.109 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,200 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,200 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,200 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,200 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,216 INFO codegen.CodeGenerator: Code generated in 8.226324 ms\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,226 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,228 INFO scheduler.DAGScheduler: Got job 21 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,228 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,228 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,229 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,229 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[124] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,231 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 11.1 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,232 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1457.0 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,233 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.129.184:44881 (size: 5.5 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,233 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,234 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[124] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,234 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,239 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.129.184:44881 in memory (size: 16.7 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,239 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,248 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:40675 in memory (size: 16.7 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,280 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:40675 (size: 5.5 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,285 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.0.129.184:60058\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,313 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 74 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,314 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,315 INFO scheduler.DAGScheduler: ResultStage 31 (count at StatsGenerator.scala:66) finished in 0.084 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,315 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,315 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,316 INFO scheduler.DAGScheduler: Job 21 finished: count at StatsGenerator.scala:66, took 0.088180 s\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,357 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:40675 in memory (size: 23.4 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,363 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.129.184:44881 in memory (size: 23.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,416 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:40675 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,416 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.129.184:44881 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,450 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:40675 in memory (size: 14.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,452 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.129.184:44881 in memory (size: 14.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,499 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.129.184:44881 in memory (size: 40.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,503 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:40675 in memory (size: 40.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,514 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:40675 in memory (size: 25.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,520 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.129.184:44881 in memory (size: 25.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,530 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.129.184:44881 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,531 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:40675 in memory (size: 3.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,537 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.129.184:44881 in memory (size: 14.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,538 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:40675 in memory (size: 14.0 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,550 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:40675 in memory (size: 20.8 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,553 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.129.184:44881 in memory (size: 20.8 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,562 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.129.184:44881 in memory (size: 16.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,564 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:40675 in memory (size: 16.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,583 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,601 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,624 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,624 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,633 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,650 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,685 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,716 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,739 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,743 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,833 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,833 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,833 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,869 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,870 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-ad13071a-ba79-43c9-aea0-927f0b002d3b\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,886 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-56c15ca6-32a1-46bc-a3dd-dce83a3e000c\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,970 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2024-10-16 23:29:01,970 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7fc32cf9bf10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_monitor.suggest_baseline(\n",
    "    baseline_dataset=f's3://{session.default_bucket()}/data/train.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, provide the monitoring schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "my_monitor.create_monitoring_schedule(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you configured Model Monitor to watch a simple model. Next, we'll monitor the same deployment for explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. If you aren't going to follow up with the Clarify exercise within a few hours, use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarify\n",
    "\n",
    "For the last exercise we'll deploy an explainability monitor using Clarify. We're going to use the model that you deployed in the last exercise, but if you cleaned up your deployments from the previous exercise, that's ok! You can rerun the deployment from the previous exercise up to the point where we deployed our model. It'll look like this:\n",
    "\n",
    "```python\n",
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")\n",
    "```\n",
    "\n",
    "Once your model is deployed, you can come back here. _REMINDER_: you need to clean up your deployment, don't leave it running overnight. We'll provide some code at the end to delete your deployment.\n",
    "\n",
    "## Prep\n",
    "\n",
    "We'll begin by reloading our data from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our data is staged and our model is deployed - let's monitor it for explainability. We need to define three config objects, the `SHAPConfig`, the `ModelConfig`, and the `ExplainabilityAnalysisConfig`. Below, we provide the `SHAPConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[train.mean().astype(int).to_list()[1:]],\n",
    "    num_samples=int(train.size),\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, fill in the blanks to define the `ModelConfig` and `ExplainabilityAnalysisConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=model.model_data,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    instance_count=1,\n",
    "    accept_type='text/csv',\n",
    "    content_type='text/csv',\n",
    ")\n",
    "\n",
    "analysis_config = sagemaker.model_monitor.ExplainabilityAnalysisConfig(\n",
    "    explainability_config=shap_config,\n",
    "    model_config=model_config,\n",
    "    headers=train.columns.to_list(),\n",
    "    dataset_type='text/csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply our config, we need to create the monitor object. This is what we'll apply all our config to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor = sagemaker.model_monitor.ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything's ready! Below, create a monitoring schedule using the configs we created. Set the schedule to run _daily_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "\n",
    "explainability_uri = f\"s3://{bucket}/lesson4-sagemaker/feature-store/explainability\"\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=explainability_uri,\n",
    "    analysis_config=analysis_config,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way to go! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you deployed a monitor for explainability to your SageMaker endpoint. This is the last exercise - you'll apply these learnings again in your Project at the end of the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. Use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
