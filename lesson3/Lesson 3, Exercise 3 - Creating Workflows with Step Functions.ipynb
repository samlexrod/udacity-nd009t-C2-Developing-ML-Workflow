{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# UDACITY Designing Your First Workflow - Step Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Step Functions & SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "In the prior exercises, we've been working with many small services. This can be overwhelming for a data scientist that wants to establish a consistent methodology for handling data. Step Functions is an orchestration service that can allow us to utilize SageMaker in a methodical and consistent way. Step Functions also integrates with Lambda, which can allow us to potentially automate our entire machine learning pipeline end-to-end. Let's get a handle on what a 'step' in a step function looks like.\n",
    "\n",
    "In this exercise, you will create a preprocessing step and a training step. Then you will create a step function to chain the two steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Exercise: Grant Permissions and install packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Attach the IAMFullAccess and the StepFunctionsFullAccess polices to your SageMaker execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install stepfunctions -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Exercise: Fill out preprocessing step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "The 'step' interface is designed to be quite similar to the Preprocessing Job in lesson 2. The main difference between these is the ability of a 'step' to interface with other steps. Given the successful outcome of a single step, the next step specified in a workflow will automatically continue. In our case, a training step will launch given the successful outcome of a preprocessing step. The preprocessing step has been encoded for you. Upload the preprocessing code 'HelloBlazePreprocess.py' and the zipped dataset 'reviews_Musical_Instruments_5.json.zip' to s3, and fill out the constants in the code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Code below is the preprocessing step. Fill in the constants in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(\n",
    "    \"HelloBlazePreprocess.py\",\n",
    "    Bucket=\"udacity-landingzone\",\n",
    "    Key=\"lesson3-stepfunction/script/HelloBlazePreprocess.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from stepfunctions.steps.sagemaker import ProcessingStep\n",
    "import sagemaker\n",
    "import time\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "timestamp = int(time.time())\n",
    "PREPROCESSING_JOB_NAME = f\"PreprocessingJob-{timestamp}\"\n",
    "TRAINING_JOB_NAME = f\"TrainingJob-{timestamp}\"\n",
    "\n",
    "input_data = 's3://udacity-landingzone/lesson3-stepfunction/input/Toys_and_Games_5.json.zip'\n",
    "input_preprocessing_code = 's3://udacity-landingzone/lesson3-stepfunction/script/HelloBlazePreprocess.py'\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.large',\n",
    "                                     instance_count=1)\n",
    "\n",
    "\n",
    "training_bucket = 'udacity-landingzone'\n",
    "suffix = \"lesson3-stepfunction/output/\"\n",
    "processed_data_train = \"{}{}/{}\".format(\"s3://\", training_bucket, suffix + \"Toys_and_Games_5.json.zip_train\")\n",
    "processed_data_test = \"{}{}/{}\".format(\"s3://\", training_bucket, suffix + \"Toys_and_Games_5.json.zip_test\")\n",
    "\n",
    "inputs=[\n",
    "    ProcessingInput(\n",
    "        source=input_data, \n",
    "        destination='/opt/ml/processing/input', \n",
    "        input_name = 'input-1'),  \n",
    "    ProcessingInput(\n",
    "        source=input_preprocessing_code , \n",
    "        destination='/opt/ml/processing/input/script', \n",
    "        input_name = 'code')]\n",
    "\n",
    "\n",
    "outputs=[\n",
    "    ProcessingOutput(\n",
    "        source='/opt/ml/processing/output/train', \n",
    "        destination=processed_data_train, \n",
    "        output_name = 'train_data'), \n",
    "    ProcessingOutput(\n",
    "        source='/opt/ml/processing/output/test', \n",
    "        destination=processed_data_test, \n",
    "        output_name = 'test_data')\n",
    "]\n",
    "\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    \"SageMaker pre-processing step 4\",\n",
    "    processor=sklearn_processor,\n",
    "    job_name=PREPROCESSING_JOB_NAME,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    container_entrypoint=[\"python3\", \"/opt/ml/processing/input/script/HelloBlazePreprocess.py\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Exercise: Fill out Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Upon the success of the preprocessing step, we wish to execute a training step. A training step is defined below. Fill the constants in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stepfunctions.steps.sagemaker import TrainingStep\n",
    "import boto3\n",
    "\n",
    "WORKFLOW_OUTPUT = \"s3://udacity-landingzone/lesson3-stepfunction/workflow/\"\n",
    "\n",
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=region_name, framework=\"blazingtext\", version=\"latest\"\n",
    ")\n",
    "\n",
    "helloBlazeEstimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size=30,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=WORKFLOW_OUTPUT,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "helloBlazeEstimator.set_hyperparameters(mode='supervised')\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    \"SageMaker Training Step\",\n",
    "    estimator=helloBlazeEstimator,\n",
    "    data={\n",
    "        \"train\": sagemaker.TrainingInput(processed_data_train, content_type=\"text/plain\"), \n",
    "        \"validation\": sagemaker.TrainingInput(processed_data_test, content_type=\"text/plain\")},\n",
    "    job_name=TRAINING_JOB_NAME,\n",
    "    wait_for_completion=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Exercise: Create Workflow & Execute It. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "To link the steps, you'll need to create a role that is capable of doing so. Go to IAM and create a Step Functions role, and attach the CloudWatchEventsFullAccess and SageMakerFullAccess policies. Once done, make use of the above steps to create a workflow. Quick debugging tip: jobs must have a unique name; you'll need to rename job names when debugging. Consider creating a method that will dynamically create unique job names! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PREPROCESSING_JOB_NAME)\n",
    "print(TRAINING_JOB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from stepfunctions.steps import Chain\n",
    "from stepfunctions.workflow import Workflow\n",
    "import time\n",
    "\n",
    "workflow_role = \"arn:aws:iam::002427974286:role/UdacitySageMakerStepFunctionExecutionRole\"\n",
    "workflow_name = \"workflow-stepfunction-processing\"  # This is the state machine name\n",
    "\n",
    "# CloudWatch Logs configuration\n",
    "log_group_arn = \"arn:aws:logs:us-east-1:002427974286:log-group:/aws/vendedlogs/states/workflow-stepfunction-processing-Logs:*\"  # Replace with your log group ARN\n",
    "\n",
    "logging_configuration = {\n",
    "    \"level\": \"ALL\",  # Log levels: ALL, ERROR, FATAL\n",
    "    \"includeExecutionData\": True,\n",
    "    \"destinations\": [\n",
    "        {\n",
    "            \"cloudWatchLogsLogGroup\": {\n",
    "                \"logGroupArn\": log_group_arn\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create boto3 client for Step Functions\n",
    "sfn_client = boto3.client('stepfunctions')\n",
    "\n",
    "# Check if the workflow (state machine) already exists\n",
    "def get_existing_workflow_arn(name):\n",
    "    state_machines = sfn_client.list_state_machines()[\"stateMachines\"]\n",
    "    for sm in state_machines:\n",
    "        if sm[\"name\"] == name:\n",
    "            return sm[\"stateMachineArn\"]\n",
    "    return None\n",
    "\n",
    "# Define the workflow graph\n",
    "workflow_graph = Chain([processing_step, training_step])\n",
    "\n",
    "# Check if workflow exists, get its ARN if it exists\n",
    "workflow_arn = get_existing_workflow_arn(workflow_name)\n",
    "\n",
    "# Create or update the workflow\n",
    "if workflow_arn:\n",
    "    print(f\"Attaching to existing workflow: {workflow_name}\")\n",
    "    # Attach to the existing workflow using its ARN\n",
    "    workflow = Workflow.attach(workflow_arn)\n",
    "    # Update the workflow definition using the Workflow object\n",
    "    workflow.update(definition=workflow_graph, role=workflow_role)\n",
    "    \n",
    "    # Update logging configuration via boto3 client\n",
    "    response = sfn_client.update_state_machine(\n",
    "        stateMachineArn=workflow_arn,\n",
    "        loggingConfiguration=logging_configuration\n",
    "    )\n",
    "    print(f\"Updated workflow with logging: {response}\")\n",
    "else:\n",
    "    print(f\"Creating new workflow: {workflow_name}\")\n",
    "    # Create a new workflow\n",
    "    workflow = Workflow(\n",
    "        name=workflow_name,\n",
    "        definition=workflow_graph,\n",
    "        role=workflow_role,\n",
    "    )\n",
    "    workflow.create()\n",
    "    \n",
    "    # Add logging configuration after creating the workflow via boto3 client\n",
    "    workflow_arn = workflow.arn\n",
    "    response = sfn_client.update_state_machine(\n",
    "        stateMachineArn=workflow_arn,\n",
    "        loggingConfiguration=logging_configuration\n",
    "    )\n",
    "    print(f\"Created workflow with logging: {response}\")\n",
    "\n",
    "# Execute the workflow with unique job names\n",
    "execution = workflow.execute(\n",
    "    inputs={\n",
    "        \"PreprocessingJobName\": PREPROCESSING_JOB_NAME,\n",
    "        \"TrainingJobName\": TRAINING_JOB_NAME\n",
    "    }\n",
    ")\n",
    "\n",
    "execution_output = execution.get_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "You can track the outcome of this workflow through a custom UI that gets generated! Check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.render_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
